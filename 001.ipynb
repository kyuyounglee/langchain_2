{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain_community openai python-dotenv duckduckgo-search  google-api-python-client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b73fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AIzaS', 'b3779')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "os.environ['GOOLE_API_KEY'][:5], os.environ['GOOGLE_CSE_ID'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04021",
   "metadata": {},
   "source": [
    "랭체인 에이전트 툴 (검색은 google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af654c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use GoogleSearch to find relevant articles about major issues in Korea.\n",
      "Action: GoogleSearch\n",
      "Action Input: \"한국의 주요 이슈\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m제목: [지급결제조사자료 2022-3] 암호자산 규제 관련 주요 이슈 및 입법 방향\n",
      "요약: 한국은행 BANK OF KOREA · 한국은행 · 한국은행이 하는 일 · 설립목적 및 역사 · 한국은행법의 변천 ...\n",
      "링크: https://www.bok.or.kr/portal/bbs/B0000232/view.do?nttId=10074134&menuNo=200706&pageIndex=1\n",
      "\n",
      "\n",
      "제목: 멕시코 대선의 주요 이슈와 한국에 주는 시사점\n",
      "요약: 2024. 5. 29. ... 본고에서는 현재 지지율 1, 2위를 기록 중인 셰인바움 후보와 갈베스 후보의 무역·통상 관련 주요 공약, 미국-멕시코. 간 무역·통상 이슈에 대한 두 후보 ...\n",
      "링크: https://www.kiep.go.kr/galleryDownload.es?bid=0004&list_no=11314&seq=1\n",
      "\n",
      "\n",
      "제목: 물적분할과 모자기업 동시상장의 주요 이슈 | | 보고서 | 자본시장연구원\n",
      "요약: 2022. 6. 2. ... 최근 상장기업의 물적분할과 쪼개기상장이 사회적 이슈로 부상되었으나 대부분의 논의가 일부 대기업 사례에만 국한되어 있다.\n",
      "링크: https://www.kcmi.re.kr/report/report_view?report_no=1489\n",
      "\n",
      "\n",
      "제목: 멕시코 대선의 주요 이슈와 한국에 주는 시사점 | KIEP 세계경제 ...\n",
      "요약: 2024. 5. 29. ... ▷ 미국-멕시코 간 주요 이슈로 △중국의 대(對)미국 우회 수출 증가, △멕시코의 에너지 정책, △USMCA 및 북미 공급망, △이민 등을 꼽을 수 있음.\n",
      "링크: https://www.kiep.go.kr/gallery.es?mid=a10102030000&bid=0004&list_no=11314&act=view\n",
      "\n",
      "\n",
      "제목: [2021-4] 중소기업 R&D 지원 방식의 주요 이슈와 정책제언 | 전체브리프\n",
      "요약: 2021. 5. 10. ... KISTEP 한국과학기술기획평가원,[2021-4] 중소기업 R&D 지원 방식의 주요 이슈와 정책제언 | 전체브리프 | KISTEP 브리프 | KISTEP 발간물.\n",
      "링크: https://www.kistep.re.kr/board.es?mid=a10306010000&bid=0031&b_list=10&act=view&list_no=42025&nPage=1&keyField=&orderby=\n",
      "\n",
      "\n",
      "제목: 한·아프리카재단 / 아프리카 지식정보 / KAF 자료실 / 아프리카 주요 ...\n",
      "요약: [아프리카 주요이슈 브리핑 2023-2호] 한국의 아프리카 방위산업 수출 전략에 대한 연구. 2023.07 ...\n",
      "링크: https://www.k-af.or.kr/load.asp?subPage=736\n",
      "\n",
      "\n",
      "제목: 이슈 | 연합뉴스\n",
      "요약: 이슈 | 정치, 북한, 경제, IT, 사회, 세계, 스포츠/연예 기사입니다.\n",
      "링크: https://www.yna.co.kr/issue/index\n",
      "\n",
      "\n",
      "제목: 전기차와 배터리산업의 주요 이슈와 시사점 | 국내연구자료 | KDI 경제 ...\n",
      "요약: 2024. 9. 13. ... 배터리를 가장 많이 소비하는 배터리 전기차의 판매 증가세 둔화로 배터리 판매 성장세도 낮아지고 있지만, 다른 전동화 차량의 판매가 급증하면서 배터리 ...\n",
      "링크: https://eiec.kdi.re.kr/policy/domesticView.do?ac=0000188043\n",
      "\n",
      "\n",
      "제목: 2025년 미국경제 전망 및 주요 이슈 상세보기|뉴욕/미국경제 | 주뉴욕 ...\n",
      "요약: 2024. 12. 27. ... 이 누리집은 대한민국 공식 전자 ...\n",
      "링크: https://overseas.mofa.go.kr/us-newyork-ko/brd/m_4242/view.do?seq=1322333\n",
      "\n",
      "\n",
      "제목: [현대경제연구원] 한국의 소재·부품·장비 산업 현황과 주요 이슈\n",
      "요약: 교역 역시 부품 산업이 소부장 산업 전체 수출의 62.7%, 수입의 57.8%, 무역수지 흑자의 74.5%를 차지할 정도로 의존도가 높다. 이에 본고에서는 소부장 산업의 이슈를 ...\n",
      "링크: https://nexus.ulsan.ac.kr/home/board/research/details/?schCode=DT000000000060\n",
      "\u001b[0m\n",
      "Thought:관련 자료를 찾을수 없습니다. : \n",
      "\n",
      "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: ` Now that I have found multiple articles about major issues in Korea, I should read through them and take notes on the main points.\n",
      "Action: Reading and taking notes on the articles.`\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# OpenAI LLM 설정\n",
    "llm = OpenAI(temperature=0.3)\n",
    "\n",
    "\n",
    "\n",
    "def google_search(query, api_key, cse_id):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    res = service.cse().list(\n",
    "        q=query,\n",
    "        cx=cse_id,\n",
    "        lr='lang_ko',\n",
    "        hl='ko',\n",
    "        gl='kr'\n",
    "    ).execute()\n",
    "    items = res.get('items', [])\n",
    "    results_text = []\n",
    "    for item in items:\n",
    "        title = item.get('title')\n",
    "        snippet = item.get('snippet')\n",
    "        link = item.get('link')\n",
    "        results_text.append(f\"제목: {title}\\n요약: {snippet}\\n링크: {link}\\n\")\n",
    "    return \"\\n\\n\".join(results_text)\n",
    "\n",
    "# Tool 등록 예\n",
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"GoogleSearch\",\n",
    "        func=lambda q: google_search(q, os.environ['GOOLE_API_KEY'], os.environ['GOOGLE_CSE_ID']),\n",
    "        description=(\n",
    "            \"이 도구는 입력된 한글 쿼리로 구글 한국어 검색을 수행합니다. \"\n",
    "            \"검색 결과로 각 문서의 제목, 요약, 링크를 제공합니다. \"\n",
    "            \"당신은 이 결과들을 종합해 질문에 대해 상세하고 구체적인 한글 답변을 만들어야 합니다. \"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# RAG 에이전트 초기화\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "# 사용자의 질문에 대해 응답 처리\n",
    "prompt_prefix = \"아래 검색 결과를 참고하여 한국어로 상세하고 자연스럽게 답변해 주세요.\\n\"\n",
    "\n",
    "user_input = \"한국의 주요 이슈를 한국어로 자세히 알려줘.\"\n",
    "try:\n",
    "    response = agent.run(prompt_prefix + user_input)\n",
    "except Exception as e:\n",
    "    print(f'관련 자료를 찾을수 없습니다. : \\n\\n{e}')\n",
    "else:\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb0a55",
   "metadata": {},
   "source": [
    "# 수업코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86d0d5",
   "metadata": {},
   "source": [
    "## Pinecone 기반 RAG 구현을 위한 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a642cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (1.82.1)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-pinecone in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pinecone in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pinecone-client) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pinecone-client) (2.4.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain_community) (3.10.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-pinecone) (0.3.19)\n",
      "Requirement already satisfied: pytest<9,>=7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.5)\n",
      "Requirement already satisfied: pytest-asyncio<1,>=0.20 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\n",
      "Requirement already satisfied: syrupy<5,>=4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.1)\n",
      "Requirement already satisfied: pytest-socket<1,>=0.6.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.4.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pinecone 6.0.2 does not provide the extra 'async'\n"
     ]
    }
   ],
   "source": [
    "%pip install openai pinecone-client langchain langchain-openai langchain_community langchain-pinecone python-dotenv pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env 파일의 환경변수 로드\n",
    "\n",
    "# Pinecone 연결 및 인덱스 초기화\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "# API 키와 환경명 가져오기\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "pc = PineconeClient(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "\n",
    "# 사용할 인덱스 이름과 임베딩 차원 설정\n",
    "index_name = \"example-index\"\n",
    "embedding_dim = 1536  # text-embedding-3-small의 벡터 차원\n",
    "\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# 인덱스 생성 (없으면 새로 생성, 이미 존재하면 넘어감)\n",
    "# 연결된 임베딩 모델의 벡터차원과 학습시 사용한 알고리즘(cosine, euclidean, dotproduct) 종류를 맞춰줘야함.. \n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 인덱스 객체 연결\n",
    "index = pc.Index(index_name)\n",
    "# OpenAI 임베딩 모델 설정 (text-embedding-3-small 사용)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97f2a8",
   "metadata": {},
   "source": [
    "## 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302e6f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 벡터 DB 내 벡터 개수: 0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 예시 문서 생성 (내용과 메타데이터)\n",
    "doc1 = Document(page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "                metadata={\"source\": \"tweet\"})\n",
    "doc2 = Document(page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "                metadata={\"source\": \"news\"})\n",
    "doc3 = Document(page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "                metadata={\"source\": \"tweet\"})\n",
    "\n",
    "# 벡터스토어 초기화 (PineconeVectorStore에 Pinecone 인덱스와 임베딩 객체 연결)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "# 문서들을 벡터 임베딩하여 Pinecone에 저장\n",
    "vector_store.add_documents([doc1, doc2, doc3])\n",
    "# 비동기라 실제반영에 시간이 걸릴수 있음\n",
    "print(f\"현재 벡터 DB 내 벡터 개수: {index.describe_index_stats()['total_vector_count']}\")  # 벡터 총량 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40207887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 3}},\n",
      " 'total_vector_count': 3,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008893fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 벡터 DB 내 벡터 개수: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"현재 벡터 DB 내 벡터 개수: {index.describe_index_stats()['total_vector_count']}\")  # 벡터 총량 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993a60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색은 넓게 -> 상위랭크로 재 정럴 하는 전략이 필요해 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560e0cd",
   "metadata": {},
   "source": [
    "## 데이터 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36ad4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/2 [tzdata]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   ---------------------------------------- 2/2 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95c130f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>director</th>\n",
       "      <th>actors</th>\n",
       "      <th>rating</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>응답하라 1988</td>\n",
       "      <td>2015</td>\n",
       "      <td>[드라마, 코미디]</td>\n",
       "      <td>신원호</td>\n",
       "      <td>[혜리, 박보검, 류준열]</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1988년 서울, 쌍문동 이웃들 사이의 우정과 가족애를 그린 드라마.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기생충</td>\n",
       "      <td>2019</td>\n",
       "      <td>[드라마, 스릴러]</td>\n",
       "      <td>봉준호</td>\n",
       "      <td>[송강호, 이선균, 조여정]</td>\n",
       "      <td>8.6</td>\n",
       "      <td>가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  year       genre director           actors  rating  \\\n",
       "0  응답하라 1988  2015  [드라마, 코미디]      신원호   [혜리, 박보검, 류준열]     9.2   \n",
       "1        기생충  2019  [드라마, 스릴러]      봉준호  [송강호, 이선균, 조여정]     8.6   \n",
       "\n",
       "                                   synopsis  \n",
       "0    1988년 서울, 쌍문동 이웃들 사이의 우정과 가족애를 그린 드라마.  \n",
       "1  가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시를 위한 간단한 데이터프레임 생성 (실제로는 CSV를 로드)\n",
    "# df = pd.read_csv(\"KoreanDramas.csv\")  # 실제 데이터셋 사용 시\n",
    "data = [\n",
    "    {\n",
    "        \"title\": \"응답하라 1988\",\n",
    "        \"year\": 2015,\n",
    "        \"genre\": [\"드라마\", \"코미디\"],\n",
    "        \"director\": \"신원호\",\n",
    "        \"actors\": [\"혜리\", \"박보검\", \"류준열\"],\n",
    "        \"rating\": 9.2,\n",
    "        \"synopsis\": \"1988년 서울, 쌍문동 이웃들 사이의 우정과 가족애를 그린 드라마.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"기생충\",\n",
    "        \"year\": 2019,\n",
    "        \"genre\": [\"드라마\", \"스릴러\"],\n",
    "        \"director\": \"봉준호\",\n",
    "        \"actors\": [\"송강호\", \"이선균\", \"조여정\"],\n",
    "        \"rating\": 8.6,\n",
    "        \"synopsis\": \"가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.\"\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df.head(2)  # 데이터 확인 (실제로는 전체 데이터 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc309e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env 파일의 환경변수 로드\n",
    "\n",
    "# Pinecone 연결 및 인덱스 초기화\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "# API 키와 환경명 가져오기\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "pc = PineconeClient(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "\n",
    "# 사용할 인덱스 이름과 임베딩 차원 설정\n",
    "index_name = \"movie-index\"\n",
    "embedding_dim = 1536  # text-embedding-3-small의 벡터 차원\n",
    "\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# 인덱스 생성 (없으면 새로 생성, 이미 존재하면 넘어감)\n",
    "# 연결된 임베딩 모델의 벡터차원과 학습시 사용한 알고리즘(cosine, euclidean, dotproduct) 종류를 맞춰줘야함.. \n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 인덱스 객체 연결\n",
    "index = pc.Index(index_name)\n",
    "# OpenAI 임베딩 모델 설정 (text-embedding-3-small 사용)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e8108c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ff942ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1988년 서울, 쌍문동 이웃들 사이의 우정과 가족애를 그린 드라마.',\n",
       " '가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts= df.synopsis.to_list()\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b44b7406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5703d0f4-4db1-4023-a8d9-fea78b00d67e',\n",
       " 'ba4d417b-6dbb-44f0-b534-7ba60911271b']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# 벡터스토어 초기화 (PineconeVectorStore에 Pinecone 인덱스와 임베딩 객체 연결)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "docs = []\n",
    "for i, sample in enumerate(data):\n",
    "    text = sample['synopsis']            \n",
    "    del sample['synopsis']\n",
    "    sample['id'] =f'movie-{i}' \n",
    "    docs.append(Document(page_content=text, metadata=sample))\n",
    "docs    \n",
    "\n",
    "\n",
    "# docs = [Document(page_content=doc, metadata={\"source\": \"movie\"}) for doc in texts]\n",
    "# # 문서들을 벡터 임베딩하여 Pinecone에 저장\n",
    "vector_store.add_documents(docs)\n",
    "# # 비동기라 실제반영에 시간이 걸릴수 있음\n",
    "# time.sleep(2)\n",
    "# print(f\"현재 벡터 DB 내 벡터 개수: {index.describe_index_stats()['total_vector_count']}\")  # 벡터 총량 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a54103a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 벡터 DB 내 벡터 개수: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"현재 벡터 DB 내 벡터 개수: {index.describe_index_stats()['total_vector_count']}\")  # 벡터 총량 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea1fd2",
   "metadata": {},
   "source": [
    "## 생성 순서\n",
    "````\n",
    "환경 변수 로드\n",
    "    # .env 파일의 환경변수 로드\n",
    "\n",
    "벡터 DB (Pinecone) -- openai의 임베딩 모델과 결합하여 모델의 특성에 맞게(유사도,유클리드,닷프로덕트) 설정하여\n",
    "객체를 생성한다. \n",
    "이 벡터는 데이터를 serverless(aws와 같은 클라우드) 기반으로 데이터를 임베딩모델을 이용해서 벡터화하고 유사도 검색 메소드 등 다양한 메소드를 제공하는 클라우드형 벡터DB로 개인사용에 최적화 되어 있다\n",
    "상세 과정\n",
    "     Pinecone 임포트\n",
    "     Pinecone 클라이언트 초기화\n",
    "\n",
    "     사용할 인덱스 이름과 임베딩 차원 설정\n",
    "\n",
    "     인덱스 생성 (없으면 새로 생성, 이미 존재하면 넘어감)\n",
    "     연결된 임베딩 모델의 벡터차원과 학습시 사용한 알고리즘(cosine, euclidean, dotproduct) 종류를 맞춰줘야함.. \n",
    "     인덱스 객체 연결\n",
    "     OpenAI 임베딩 모델 설정 (text-embedding-3-small 사용)\n",
    "\n",
    "     Document 문서 생성 (내용과 메타데이터)\n",
    "     벡터스토어 초기화 (PineconeVectorStore에 Pinecone 인덱스와 임베딩 객체 연결)\n",
    "     문서들을 벡터 임베딩하여 Pinecone에 저장\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1f8a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81d04ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_documents([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7b2a38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ae694",
   "metadata": {},
   "source": [
    "# 쿼리 작성후 vector store에서 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f5fb8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5703d0f4-4db1-4023-a8d9-fea78b00d67e', metadata={'actors': ['혜리', '박보검', '류준열'], 'director': '신원호', 'genre': ['드라마', '코미디'], 'id': 'movie-0', 'rating': 9.2, 'title': '응답하라 1988', 'year': 2015.0}, page_content='1988년 서울, 쌍문동 이웃들 사이의 우정과 가족애를 그린 드라마.'),\n",
       " Document(id='ba4d417b-6dbb-44f0-b534-7ba60911271b', metadata={'actors': ['송강호', '이선균', '조여정'], 'director': '봉준호', 'genre': ['드라마', '스릴러'], 'id': 'movie-1', 'rating': 8.6, 'title': '기생충', 'year': 2019.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '웃긴 영화가 보고싶어.. 추천 해 주세요'\n",
    "result = vector_store.similarity_search(query,k=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d214a",
   "metadata": {},
   "source": [
    "# 임의 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ec7d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '검은 사제들 98', 'year': 1992, 'genre': ['드라마', 'SF', '미스터리'], 'director': '김지운', 'actors': ['마동석', '유재석', '수지'], 'rating': 8.8}\n",
      "{'title': '도깨비 31', 'year': 2012, 'genre': ['드라마'], 'director': '봉준호', 'actors': ['이병헌', '유아인', '박보영', '남궁민'], 'rating': 8.8}\n",
      "{'title': '무빙 87', 'year': 2018, 'genre': ['드라마'], 'director': '윤종빈', 'actors': ['남궁민', '조승우'], 'rating': 7.9}\n",
      "{'title': '해운대 9', 'year': 2013, 'genre': ['로맨스', '스릴러'], 'director': '임권택', 'actors': ['수지', '아이유', '정해인'], 'rating': 9.0}\n",
      "{'title': '올드보이 77', 'year': 2016, 'genre': ['드라마'], 'director': '임권택', 'actors': ['조승우', '김혜수', '전도연', '박보영'], 'rating': 7.6}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 샘플 데이터 정의\n",
    "titles = [\n",
    "    \"봄날은 간다\", \"명량\", \"살인의 추억\", \"부산행\", \"올드보이\", \"태극기 휘날리며\", \"추격자\", \"해운대\", \n",
    "    \"극한직업\", \"도둑들\", \"검사외전\", \"신세계\", \"범죄와의 전쟁\", \"관상\", \"7번방의 선물\", \"국제시장\",\n",
    "    \"비열한 거리\", \"검은 사제들\", \"미스터 션샤인\", \"이태원 클라쓰\", \"빈센조\", \"지옥\", \"지금 우리 학교는\", \n",
    "    \"도깨비\", \"호텔 델루나\", \"시그널\", \"비밀의 숲\", \"나의 해방일지\", \"더 글로리\", \"무빙\"\n",
    "]\n",
    "\n",
    "genres = [\"드라마\", \"코미디\", \"스릴러\", \"로맨스\", \"액션\", \"SF\", \"판타지\", \"미스터리\", \"범죄\", \"공포\"]\n",
    "directors = [\"박찬욱\", \"봉준호\", \"임권택\", \"홍상수\", \"김지운\", \"윤종빈\", \"한지민\", \"이창동\", \"최동훈\", \"신원호\"]\n",
    "actors_pool = [\"송강호\", \"이병헌\", \"전도연\", \"김혜수\", \"마동석\", \"유아인\", \"박보영\", \"아이유\", \"남궁민\", \"조승우\", \"김남길\", \"수지\", \"정해인\", \"김태리\", \"유재석\"]\n",
    "\n",
    "def generate_random_entry():\n",
    "    return {\n",
    "        \"title\": random.choice(titles) + f\" {random.randint(1, 100)}\",\n",
    "        \"year\": random.randint(1990, 2024),\n",
    "        \"genre\": random.sample(genres, k=random.randint(1, 3)),\n",
    "        \"director\": random.choice(directors),\n",
    "        \"actors\": random.sample(actors_pool, k=random.randint(2, 4)),\n",
    "        \"rating\": round(random.uniform(6.0, 9.8), 1),        \n",
    "    }\n",
    "\n",
    "# 100개의 랜덤 데이터 생성\n",
    "data = [generate_random_entry() for _ in range(100)]\n",
    "\n",
    "# 결과 예시 출력 (5개만 보기)\n",
    "for d in data[:5]:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6279b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # .env 파일의 환경변수 로드\n",
    "\n",
    "# Pinecone 연결 및 인덱스 초기화\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "\n",
    "# API 키와 환경명 가져오기\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "pc = PineconeClient(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "\n",
    "# 사용할 인덱스 이름과 임베딩 차원 설정\n",
    "index_name = \"movie2-index\"\n",
    "embedding_dim = 1536  # text-embedding-3-small의 벡터 차원\n",
    "\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# 인덱스 생성 (없으면 새로 생성, 이미 존재하면 넘어감)\n",
    "# 연결된 임베딩 모델의 벡터차원과 학습시 사용한 알고리즘(cosine, euclidean, dotproduct) 종류를 맞춰줘야함.. \n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 인덱스 객체 연결\n",
    "index = pc.Index(index_name)\n",
    "# OpenAI 임베딩 모델 설정 (text-embedding-3-small 사용)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터스토어 초기화 (PineconeVectorStore에 Pinecone 인덱스와 임베딩 객체 연결)\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store2= PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "docs = []\n",
    "for i, sample in enumerate(data):    \n",
    "    sample['id'] =f'movie-{i}' \n",
    "    docs.append(Document(page_content=text, metadata=sample))\n",
    "vector_store2.add_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fed6e76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8a6f4ba1-e929-4047-8d95-1dac0384e7d9', metadata={'actors': ['송강호', '조승우', '김태리'], 'director': '임권택', 'genre': ['공포', '드라마', '판타지'], 'id': 'movie-17', 'rating': 7.3, 'title': '나의 해방일지 75', 'year': 2002.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='da7cf323-3334-4456-aa35-625e70516de0', metadata={'actors': ['유재석', '아이유'], 'director': '신원호', 'genre': ['스릴러'], 'id': 'movie-98', 'rating': 8.0, 'title': '해운대 79', 'year': 1997.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='6e8b22b0-312d-4506-990e-f17fe0e00fca', metadata={'actors': ['남궁민', '유아인'], 'director': '김지운', 'genre': ['SF'], 'id': 'movie-69', 'rating': 9.8, 'title': '범죄와의 전쟁 44', 'year': 2005.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='78a105b2-314e-4e95-ab67-aba0d7d40334', metadata={'actors': ['유아인', '수지', '이병헌', '남궁민'], 'director': '이창동', 'genre': ['드라마'], 'id': 'movie-73', 'rating': 8.7, 'title': '나의 해방일지 77', 'year': 1997.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='d3b27533-10de-420b-932a-e2e69a46b5f5', metadata={'actors': ['유재석', '유아인'], 'director': '이창동', 'genre': ['드라마', '판타지', '스릴러'], 'id': 'movie-62', 'rating': 6.4, 'title': '시그널 11', 'year': 2022.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='c4ffc356-c4d1-42e1-9efc-bc438773978f', metadata={'actors': ['유재석', '정해인'], 'director': '이창동', 'genre': ['로맨스', '드라마'], 'id': 'movie-76', 'rating': 8.9, 'title': '국제시장 77', 'year': 2015.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='d39d0098-41f0-4398-81c8-5fe43eb7720a', metadata={'actors': ['마동석', '전도연'], 'director': '박찬욱', 'genre': ['미스터리'], 'id': 'movie-53', 'rating': 6.6, 'title': '살인의 추억 50', 'year': 2011.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='20bd0a56-a6a3-4c86-8cba-0243ec1c3fe8', metadata={'actors': ['김혜수', '정해인'], 'director': '홍상수', 'genre': ['SF'], 'id': 'movie-35', 'rating': 7.6, 'title': '비열한 거리 79', 'year': 2016.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='84ec3a52-8779-4f7d-815d-0286ffa2d13b', metadata={'actors': ['조승우', '유아인', '남궁민'], 'director': '신원호', 'genre': ['액션'], 'id': 'movie-75', 'rating': 6.6, 'title': '올드보이 66', 'year': 2017.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.'),\n",
       " Document(id='29ad7b72-b939-44f6-a225-ff59731d93bb', metadata={'actors': ['정해인', '김남길', '김혜수'], 'director': '김지운', 'genre': ['로맨스'], 'id': 'movie-95', 'rating': 6.2, 'title': '올드보이 63', 'year': 2002.0}, page_content='가난한 가족과 부유한 가족 사이 벌어지는 블랙코미디 풍자의 스릴러 영화.')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '무서운 영화가 보고싶어.. 추천 해 주세요'\n",
    "result = vector_store2.similarity_search(query,k=10)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9396f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 한글 영화 데이터셋 정의\n",
    "movies = [\n",
    "    {\n",
    "        \"id\": \"movie1\",\n",
    "        \"title\": \"7번방의 선물\",\n",
    "        \"year\": 2013,\n",
    "        \"genre\": \"드라마\",\n",
    "        \"description\": \"억울한 누명을 쓰고 교도소에 수감된 아빠와 그의 어린 딸의 감동적인 스토리\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie2\",\n",
    "        \"title\": \"미나리\",\n",
    "        \"year\": 2020,\n",
    "        \"genre\": \"드라마\",\n",
    "        \"description\": \"한국계 미국인 가족의 따뜻하고 감성적인 성장 이야기\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie3\",\n",
    "        \"title\": \"기생충\",\n",
    "        \"year\": 2019,\n",
    "        \"genre\": \"드라마\",\n",
    "        \"description\": \"가난한 가족과 부자 가족 사이의 빈부격차를 그린 사회 풍자 드라마\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie4\",\n",
    "        \"title\": \"범죄도시\",\n",
    "        \"year\": 2017,\n",
    "        \"genre\": \"범죄\",\n",
    "        \"description\": \"형사가 범죄 조직을 소탕하는 범죄 액션 영화\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie5\",\n",
    "        \"title\": \"범죄도시 2\",\n",
    "        \"year\": 2022,\n",
    "        \"genre\": \"범죄\",\n",
    "        \"description\": \"형사와 범죄 조직의 대결을 그린 범죄 액션 영화의 속편\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie6\",\n",
    "        \"title\": \"헤어질 결심\",\n",
    "        \"year\": 2022,\n",
    "        \"genre\": \"범죄\",\n",
    "        \"description\": \"산에서 발생한 의문의 죽음(살인 사건)을 수사하던 형사가 피의자에게 이끌리며 벌어지는 미스터리 멜로 영화\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"movie7\",\n",
    "        \"title\": \"다만 악에서 구하소서\",\n",
    "        \"year\": 2020,\n",
    "        \"genre\": \"범죄\",\n",
    "        \"description\": \"청부 살인업자와 범죄 조직의 마지막 거래를 그린 범죄 액션 영화\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3cc79b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\511-17\\AppData\\Local\\Temp\\ipykernel_9052\\3303327196.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터 차원: 1536\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 객체 생성 (모델명과 API 키 지정)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# 모든 영화 설명에 대해 임베딩 벡터 생성\n",
    "descriptions = [movie[\"description\"] for movie in movies]        # 설명문 리스트\n",
    "movie_vectors = embeddings.embed_documents(descriptions)         # 각 설명문에 대한 임베딩 벡터 리스트 생성\n",
    "\n",
    "# 임베딩 벡터의 차원 확인 (예상: 1536차원)\n",
    "print(f\"임베딩 벡터 차원: {len(movie_vectors[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c24379cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키와 환경명 가져오기\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "pc = PineconeClient(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "index_name = \"movie-vector-index\"\n",
    "embedding_dim = 1536\n",
    "# Pinecone 초기화 (API 키와 환경은 이미 os.environ에 설정됨)\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 인덱스 이름과 차원 설정\n",
    "index_name = \"movie-vector-index\"\n",
    "\n",
    "# 기존에 동일 이름의 인덱스가 있으면 삭제 (재실행 시 중복 방지용)\n",
    "if index_name in pc.list_indexes():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# 인덱스 객체에 연결\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08627f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 7}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pinecone에 벡터 업로드 (upsert)\n",
    "# 각 레코드는 (id, 벡터, metadata)의 형태로 준비\n",
    "vector_data = []\n",
    "for movie, vector in zip(movies, movie_vectors):\n",
    "    # metadata로 title, genre, year, description 저장\n",
    "    meta = {\n",
    "        \"title\": movie[\"title\"],\n",
    "        \"genre\": movie[\"genre\"],\n",
    "        \"year\": movie[\"year\"],\n",
    "        \"description\": movie[\"description\"]\n",
    "    }\n",
    "    vector_data.append((movie[\"id\"], vector, meta))\n",
    "\n",
    "# 벡터들을 Pinecone 인덱스에 업서트\n",
    "index.upsert(vectors=vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e55a3f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기생충 - 2019.0 (드라마)\n",
      "7번방의 선물 - 2013.0 (드라마)\n",
      "범죄도시 - 2017.0 (범죄)\n"
     ]
    }
   ],
   "source": [
    "# 검색 쿼리 예시\n",
    "query_text = \"감성적인 드라마 영화 추천해줘\"\n",
    "\n",
    "# 쿼리 문장을 임베딩 벡터로 변환\n",
    "query_vector = embeddings.embed_query(query_text)\n",
    "\n",
    "# Pinecone에서 벡터 유사도 검색 수행 (코사인 유사도 기반)\n",
    "# 상위 3개의 가장 가까운 벡터를 찾고, 메타데이터를 포함하여 반환\n",
    "result = index.query(vector=query_vector, top_k=3, include_metadata=True)\n",
    "\n",
    "# 결과 출력: 각 결과의 제목, 연도, 장르를 표시\n",
    "for match in result[\"matches\"]:\n",
    "    info = match[\"metadata\"]\n",
    "    print(f\"{info['title']} - {info['year']} ({info['genre']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b0d938c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "범죄도시 2 - 2022.0 (범죄)\n",
      "헤어질 결심 - 2022.0 (범죄)\n",
      "다만 악에서 구하소서 - 2020.0 (범죄)\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 필터를 활용한 검색: 2020년 이후 개봉한 영화들 중 상위 3개 반환\n",
    "query_text2 = \"영화\"  # 매우 일반적인 쿼리\n",
    "query_vector2 = embeddings.embed_query(query_text2)\n",
    "\n",
    "# year 필터 적용 (year >= 2020인 항목만 대상)\n",
    "filter_condition = {\"year\": {\"$gte\": 2020}}\n",
    "\n",
    "result2 = index.query(vector=query_vector2, top_k=3, filter=filter_condition, include_metadata=True)\n",
    "\n",
    "for match in result2[\"matches\"]:\n",
    "    info = match[\"metadata\"]\n",
    "    print(f\"{info['title']} - {info['year']} ({info['genre']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb71b475",
   "metadata": {},
   "source": [
    "#  - 정리 - \n",
    "```\n",
    "기본환경설정\n",
    "데이터 수집\n",
    "벡터DB 선택\n",
    "쿼리 작성 및 결과 확인\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "85317500",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'wiki'\n",
    "demention = 1536\n",
    "metric = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4fb7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (2.2.6)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.32.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading huggingface_hub-0.32.3-py3-none-any.whl (512 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 13.6/25.7 MB 71.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.6/25.7 MB 71.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.7 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 39.6 MB/s eta 0:00:00\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, fsspec, filelock, dill, multiprocess, huggingface-hub, datasets\n",
      "\n",
      "   ----- ---------------------------------- 1/8 [pyarrow]\n",
      "   ----- ---------------------------------- 1/8 [pyarrow]\n",
      "   ----- ---------------------------------- 1/8 [pyarrow]\n",
      "   ----- ---------------------------------- 1/8 [pyarrow]\n",
      "   ----- ---------------------------------- 1/8 [pyarrow]\n",
      "   ---------- ----------------------------- 2/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [dill]\n",
      "   ------------------------- -------------- 5/8 [multiprocess]\n",
      "   ------------------------------ --------- 6/8 [huggingface-hub]\n",
      "   ------------------------------ --------- 6/8 [huggingface-hub]\n",
      "   ----------------------------------- ---- 7/8 [datasets]\n",
      "   ----------------------------------- ---- 7/8 [datasets]\n",
      "   ----------------------------------- ---- 7/8 [datasets]\n",
      "   ---------------------------------------- 8/8 [datasets]\n",
      "\n",
      "Successfully installed datasets-3.6.0 dill-0.3.8 filelock-3.18.0 fsspec-2025.3.0 huggingface-hub-0.32.3 multiprocess-0.70.16 pyarrow-20.0.0 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8ca206f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  데이터 수집집\n",
    "from datasets import load_dataset\n",
    "data = load_dataset('wikipedia','20220301.simple',split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e07cd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키와 환경명 가져오기\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_env = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "\n",
    "# Pinecone 클라이언트 초기화\n",
    "pc = PineconeClient(api_key=pinecone_api_key, environment=pinecone_env)\n",
    "index_name = \"movie-vector-index\"\n",
    "embedding_dim = 1536\n",
    "# Pinecone 초기화 (API 키와 환경은 이미 os.environ에 설정됨)\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 인덱스 이름과 차원 설정\n",
    "index_name = \"movie-vector-index\"\n",
    "\n",
    "# 기존에 동일 이름의 인덱스가 있으면 삭제 (재실행 시 중복 방지용)\n",
    "if index_name in pc.list_indexes():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# 인덱스 객체에 연결\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "##################################################\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# OpenAIEmbeddings 객체 생성 (모델명과 API 키 지정)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20,separators=['\\n\\n','\\n'])\n",
    "texts,metas,batch_size = [],[],100\n",
    "for i ,sample in enumerate(data):\n",
    "    text = sample.pop('text')\n",
    "    chunk_text = text_splitter.split_text(text)    \n",
    "    for i, chunk in enumerate(chunk_text):\n",
    "        record = {\n",
    "            'chunk_id' : i,\n",
    "            'text' : text,\n",
    "            **sample\n",
    "        }\n",
    "        texts.append(chunk_text)\n",
    "        metas.append(record)\n",
    "        if (i+1) % batch_size == 0:\n",
    "            vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "            # 벡터화\n",
    "            # index에 upset\n",
    "# 미 완성......................    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_part_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
